{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import numpy as np\n",
    "from itertools import count, chain\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, device):\n",
    "        super(CustomEnv, self).__init__()\n",
    "        self.loadData()\n",
    "        #TODO: Normalization needed\n",
    "#         self.curves # [\n",
    "#                         [ #image0\n",
    "#                          [[x,y],....],[#organ1.........],.....\n",
    "#                         ],......#100,000\n",
    "#                        ]\n",
    "\n",
    "#         self.samples # [\n",
    "#                         [ #image0\n",
    "#                          [1.54, 1.2,....],[#organ1 1.54, 1.2,....],.....#6\n",
    "#                         ],......#100,000\n",
    "#                        ]\n",
    "#         self.max_list #8\n",
    "#         self.min_list #8\n",
    "#         self.estimators #6\n",
    "#         self.eigen_cmps = #torso_eigen_cmps\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.MAX_STEPS = 9\n",
    "        self.device = device\n",
    "\n",
    "        \n",
    "        self.all_spaces = spaces.Tuple((spaces.Discrete(9), spaces.Discrete(8)))\n",
    "        self.action_space = spaces.Tuple((spaces.Discrete(9), spaces.Discrete(8)))\n",
    "        self.observation_space = spaces.Tuple((spaces.Box(low=0, high=1.0, \n",
    "                                                          shape=(self.torso_d*3+self.lung_d*3+self.sp_d*2+1,), \n",
    "                                                          dtype=np.float16) ))\n",
    "        \n",
    "#     def create_training_gr_pos_file(self):\n",
    "#         f = open('/content/drive/My Drive/pgnn/BMDSXY_NODES_POS.txt', \"r\")\n",
    "#         self.data_pos = {}\n",
    "#         for i,curve in enumerate(f):\n",
    "#             self.data_pos[i] = np.reshape(np.array([int(x) for x in curve.split()]), (-1,2))\n",
    "\n",
    "    def step(self, action):\n",
    "        # Execute one time step within the environment\n",
    "        self._take_action(action)\n",
    "        self.current_step += 1\n",
    "        # if self.current_step > len(self.df.loc[:, 'Open'].values) - 6:\n",
    "        if self.current_step > self.MAX_STEPS:  #RESET\n",
    "            # we are not checking for 'no action' action since longer routes \n",
    "            # would mean larger rewards\n",
    "            self.current_step = 0\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        delay_modifier = (self.current_step / self.MAX_STEPS) #DEFINE\n",
    "        \n",
    "        torso = Polygon([self.curves_int[0][index] for index in co_in])\n",
    "        \n",
    "        if torso.contains(leftlung) and torso.contains(rightlung) and torso.contains(heart) \\\n",
    "        and torso.contains(esophagus):\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 0\n",
    "                \n",
    "        reward = reward * delay_modifier\n",
    "\n",
    "        # print()\n",
    "        # print('REWARD  ' + str(reward))\n",
    "        # done = self.net_worth <= 0\n",
    "        return self.__preprocess_actor_critic_input(self.current_l_dim, self.input_l_dim),  reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.selected_idx1 = np.random.randrange(len(self.samples))\n",
    "        self.selected_idx2 = np.random.randrange(len(self.samples))\n",
    "        self.int_level = np.random.randrange(3)\n",
    "        self.samples_img1 = self.samples[self.selected_idx1]\n",
    "        self.samples_img2 = self.samples[self.selected_idx2]\n",
    "        self.curves_img1 = self.curves[self.selected_idx1]\n",
    "        self.curves_img2 = self.curves[self.selected_idx2]\n",
    "        self.samples_int = [] \n",
    "        self.samples_chain = [] \n",
    "        for sample1,sample2 in zip(self.samples_img1, self.samples_img2):\n",
    "            if int_level == 0:\n",
    "                self.samples_int.append(0.7*sample1 + 0.3*sample2)\n",
    "            elif int_level == 1:\n",
    "                self.samples_int.append(0.5*sample1 + 0.5*sample2)\n",
    "            else:\n",
    "                self.samples_int.append(0.3*sample1 + 0.7*sample2)\n",
    "        self.samples_chain = [ev for org in self.samples_int for ev in org]\n",
    "        \n",
    "        self.curves_int = []\n",
    "        for org in range(6):        \n",
    "            curves_o = self.estimators[org].mean_\n",
    "            for i,val in enumerate(self.samples_int[org]):\n",
    "                curves_o = curves_o + self.estimators[org].components_[i]*val\n",
    "            curves_o = np.reshape((curves_o*255.5 + 255.5), (-1, 2)).astype(int).tolist()\n",
    "            self.curves_int.append(curves_o)\n",
    "            \n",
    "        leftlung = Polygon([self.curves_int[1][index] for index in co_in123]) #####\n",
    "        rightlung = Polygon([self.curves_int[2][index] for index in co_in123])\n",
    "        heart = Polygon([self.curves_int[3][index] for index in co_in123])\n",
    "        spinalcord = Polygon([self.curves_int[4][index] for index in co_in45])\n",
    "        esophagus = Polygon([self.curves_int[5][index] for index in co_in45])\n",
    "\n",
    "#         self.resetPosAndDims()\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             self.input_l_dim = vae.get_latent_var([self.input_graph,])\n",
    "\n",
    "        return self.__preprocess_input(self.samples_img1, self.samples_img2, self.samples_chain, \n",
    "                                                    self.int_level)\n",
    "\n",
    "#     def resetPosAndDims(self):\n",
    "\n",
    "#         pos = copy.deepcopy(self.static_shape)\n",
    "#         self.current_pos = []\n",
    "#         for i in range(36):\n",
    "#             pos[i][0] = (pos[i][0] - 255.5) / 460.0\n",
    "#             pos[i][1] = (pos[i][1] - 255.5) / 460.0\n",
    "#             self.current_pos.append(pos[i])\n",
    "#         self.current_pos = torch.FloatTensor(self.current_pos)\n",
    "#         self.setCurrentPosFeaturesAndLDim()\n",
    "    \n",
    "#     def setCurrentPosFeaturesAndLDim(self):\n",
    "\n",
    "#         x_c = self.current_pos[:,0]\n",
    "#         y_c = self.current_pos[:,1]\n",
    "\n",
    "#         eucl_dist_feat = torch.sqrt(torch.pow((x_c.repeat(36,1) - x_c.repeat(36,1).T), 2) + \\\n",
    "#                    torch.pow((y_c.repeat(36,1) - y_c.repeat(36,1).T), 2) + 0.00000001 )\n",
    "#         self.cur_eucl_angl_feat_X = (x_c.repeat(36,1) - x_c.repeat(36,1).T)/eucl_dist_feat\n",
    "#         self.cur_eucl_angl_feat_Y = (y_c.repeat(36,1) - y_c.repeat(36,1).T)/eucl_dist_feat\n",
    "#         self.reset_graph.node_features[:,36:] = torch.cat([eucl_dist_feat, self.cur_eucl_angl_feat_X, self.cur_eucl_angl_feat_Y], 1)\n",
    "#         self.vae.eval()\n",
    "#         with torch.no_grad():\n",
    "#             self.current_l_dim = vae.get_latent_var([self.reset_graph,])\n",
    "\n",
    "\n",
    "    def __preprocess_input(self, samples_img1, samples_img2, samples_chain, int_level):\n",
    "        '''FUSION WITH ONE_HOT VECTORS REPRESENTING NODES And LATENT VECTORS'''\n",
    "        \n",
    "        tor1 = samples_img1[0]\n",
    "        tor2 = samples_img2[0]\n",
    "        return np.asarray(samples_chain.extend(tor1).extend(tor2).append(int_level))\n",
    "\n",
    "#     def render(self, mode='human', close=False):\n",
    "        \n",
    "\n",
    "    \n",
    "    def _take_action(self, action):\n",
    "\n",
    "        eig_cmp = action[0]\n",
    "        eig_mod = action[1]\n",
    "        if eig_cmp != 8:\n",
    "            tor1_ev = self.samples_img1[0][eig_cmp]\n",
    "            tor2_ev = self.samples_img2[0][eig_cmp]\n",
    "            tor3_ev = self.samples_int[0][eig_cmp]\n",
    "            max_ev = max_list[eig_cmp]\n",
    "            min_ev = min_list[eig_cmp]\n",
    "            modif = [min_ev, tor1_ev, tor2_ev, max_ev]\n",
    "            if eig_mod // 2 == 0:\n",
    "                new_ev = modif[int(eig_mod / 2) // 4]*0.1 + tor3_ev*0.9\n",
    "            else:\n",
    "                new_ev = modif[int(eig_mod / 2) // 4]*0.3 + tor3_ev*0.7\n",
    "            self.samples_int[0][eig_cmp] = new_ev\n",
    "            self.samples_chain[eig_cmp] = new_ev\n",
    "            \n",
    "            curves_o = self.estimators[0].mean_\n",
    "            for i,val in enumerate(self.samples_int[0]):\n",
    "                curves_o = curves_o + self.estimators[0].components_[i]*val\n",
    "            curves_o = np.reshape((curves_o*255.5 + 255.5), (-1, 2)).astype(int).tolist()\n",
    "            self.curves_int[0] = curves_o\n",
    "                \n",
    "        # print('Action CHOSEN ' + str(action[0]) + '    ' + str(action[1]) + '    ' + str(action[2]))\n",
    "\n",
    "    def create_patient_seg_adj_dict(self):\n",
    "        n = 12\n",
    "        gap = 24\n",
    "\n",
    "        '''Creating static graph structure for all instances'''\n",
    "        self.patient_seg_adj_dict = {}\n",
    "        for i in range(n + gap):\n",
    "            self.patient_seg_adj_dict[i] = []\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i!=j:\n",
    "                    self.patient_seg_adj_dict[i].append(j)\n",
    "\n",
    "        add_co = n\n",
    "        for i in range(n):\n",
    "            self.patient_seg_adj_dict[i].append(add_co)\n",
    "            self.patient_seg_adj_dict[add_co].append(i)\n",
    "            self.patient_seg_adj_dict[add_co].append(add_co + 1)\n",
    "            self.patient_seg_adj_dict[add_co + 1].append(add_co)\n",
    "            add_co+=1\n",
    "            if i+1 != n:\n",
    "                self.patient_seg_adj_dict[i+1].append(add_co)\n",
    "                self.patient_seg_adj_dict[add_co].append(i+1)\n",
    "                add_co+=1\n",
    "            else:\n",
    "                self.patient_seg_adj_dict[0].append(add_co)\n",
    "                self.patient_seg_adj_dict[add_co].append(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
