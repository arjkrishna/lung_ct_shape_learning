{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "\n",
    "def sample(logits):\n",
    "    noise1 = tf.random_uniform(tf.shape(logits))\n",
    "#     noise2 = tf.random_uniform(tf.shape(logits))\n",
    "    # the values should be random in the beginning, so should be different\n",
    "    # in the beginning before returning usually the same actions for both\n",
    "    # what if it chooses the 'do-nothing action?'\n",
    "    # maybe just use sequence of actions as different output (8 actions = 8 output)\n",
    "    # maybe don't use this framework at all and do the alternate classifier training ( seperate \n",
    "    # usual cnns) and reinforcement learning.\n",
    "    return tf.argmax(logits - tf.log(-tf.log(3*noise1)), 1)#,\n",
    "#             tf.argmax(logits - tf.log(-tf.log(noise2)), 1)\n",
    "\n",
    "\n",
    "def fc(x, scope, nh, act=tf.nn.relu, init_scale=1.0):\n",
    "    with tf.variable_scope(scope):\n",
    "        nin = x.get_shape()[1].value\n",
    "        w = tf.get_variable(\"w\", [nin, nh], initializer=ortho_init(init_scale))\n",
    "        b = tf.get_variable(\"b\", [nh], initializer=tf.constant_initializer(0.0))\n",
    "        z = tf.matmul(x, w)+b\n",
    "        h = act(z)\n",
    "        return h\n",
    "    \n",
    "def ortho_init(scale=1.0):\n",
    "    def _ortho_init(shape, dtype, partition_info=None):\n",
    "        #lasagne ortho init for tf\n",
    "        shape = tuple(shape)\n",
    "        if len(shape) == 2:\n",
    "            flat_shape = shape\n",
    "        elif len(shape) == 4: # assumes NHWC\n",
    "            flat_shape = (np.prod(shape[:-1]), shape[-1])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        a = np.random.normal(0.0, 1.0, flat_shape)\n",
    "        u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "        q = u if u.shape == flat_shape else v # pick the one with the correct shape\n",
    "        q = q.reshape(shape)\n",
    "        return (scale * q[:shape[0], :shape[1]]).astype(np.float32)\n",
    "    return _ortho_init\n",
    "\n",
    "def cat_entropy(logits):\n",
    "    a0 = logits - tf.reduce_max(logits, 1, keepdims=True)\n",
    "    ea0 = tf.exp(a0)\n",
    "    z0 = tf.reduce_sum(ea0, 1, keepdims=True)\n",
    "    p0 = ea0 / z0\n",
    "    return tf.reduce_sum(p0 * (tf.log(z0) - a0), 1)\n",
    "\n",
    "# def cat_entropy_softmax(p0):\n",
    "#     return - tf.reduce_sum(p0 * tf.log(p0 + 1e-6), axis = 1)\n",
    "\n",
    "def mse(pred, target):\n",
    "    return tf.square(pred-target)/2.\n",
    "\n",
    "def find_trainable_variables(key):\n",
    "    with tf.variable_scope(key):\n",
    "        return tf.trainable_variables()\n",
    "\n",
    "def discount_with_dones(rewards, dones, gamma):\n",
    "    discounted = []\n",
    "    r = 0\n",
    "    for reward, done in zip(rewards[::-1], dones[::-1]):\n",
    "        r = reward + gamma * r * (1. - done)  # fixed off by one bug\n",
    "        discounted.append(r)\n",
    "    return discounted[::-1]\n",
    "\n",
    "def make_path(f):\n",
    "    return os.makedirs(f, exist_ok=True)\n",
    "\n",
    "def constant(p):\n",
    "    return 1\n",
    "\n",
    "def linear(p):\n",
    "    return 1-p\n",
    "\n",
    "def my_explained_variance(qpred, q):\n",
    "    _, vary = tf.nn.moments(q, axes=[0, 1])\n",
    "    _, varpred = tf.nn.moments(q - qpred, axes=[0, 1])\n",
    "    check_shape([vary, varpred], [[]] * 2)\n",
    "    return 1.0 - (varpred / vary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "25\n",
      "1\n",
      "1\n",
      "1\n",
      "20\n",
      "7\n",
      "2\n",
      "13\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    noise = tf.random_uniform(tf.shape((2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2)))\n",
    "    with tf.Session() as sess:  print(tf.argmax((2,8,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2) - tf.log(-tf.log(4*noise)), -1).eval()) \n",
    "    # noise[0].val\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 349,  228,   41, -251, -141,  -55,  355])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([41, 162, 349, 641, 531, 445, 35])\n",
    "B = np.array([42, 300, 323, 479, 436, 389, 36])\n",
    "C = np.array([1.4, 7, 14, 28, 70, 140])\n",
    "# A = np.where(A==41, 0.2, A)\n",
    "390-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.expand_dims(A, axis=0)\n",
    "B = np.expand_dims(B, axis=0).repeat(3, 0)\n",
    "A = np.repeat(A, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.append(A,B, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.        , 0.4       , 0.3       , 0.        ],\n",
       "        [0.4       , 0.84280203, 0.79450749, 0.8160969 ],\n",
       "        [0.3       , 0.32153768, 0.86641595, 0.85252111],\n",
       "        [0.        , 0.64638905, 0.45202816, 0.38990257],\n",
       "        [0.        , 0.4652625 , 0.7512825 , 0.01250822]]),\n",
       " array([[2.        , 0.4       , 0.3       , 0.        ],\n",
       "        [0.4       , 0.84280203, 0.79450749, 0.8160969 ],\n",
       "        [0.3       , 0.32153768, 0.86641595, 0.85252111],\n",
       "        [0.        , 0.64638905, 0.45202816, 0.38990257],\n",
       "        [0.        , 0.4652625 , 0.7512825 , 0.01250822]]))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "a = np.random.random((5, 4))\n",
    "a[0,0] = 2.0\n",
    "a[1,0] = 0.4\n",
    "a[2,0] = 0.3\n",
    "a[3,0] = 0\n",
    "a[4,0] = 00.\n",
    "\n",
    "a[0,1] = 0.4\n",
    "a[0,2] = 0.3\n",
    "a[0,3] = 0\n",
    "# print(\"Data = \", a)\n",
    "# a = a*20\n",
    "# print(\"Data = \", a)\n",
    "\n",
    "# normalize the data attributes\n",
    "normalized = preprocessing.normalize(a)\n",
    "normalized2 = preprocessing.MinMaxScaler()\n",
    "a_scaled = normalized2.fit_transform(a)\n",
    "normalized2.inverse_transform(a_scaled),a\n",
    "# print(\"Normalized Data = \", normalized)\n",
    "# print(\"Normalized Data = \", a_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
